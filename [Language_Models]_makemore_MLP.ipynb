{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vithushanms/makemore-language-model/blob/main/%5BLanguage_Models%5D_makemore_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV_VKEpC1SEs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6lGUb1f1WXO",
        "outputId": "aa93a885-be30-466c-85a1-8223f6572b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#if cloud\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataFilePath = '/content/drive/My Drive/Publications/Neural Networks Research/makemore: next char prediction language model/names.txt'\n",
        "words = open(dataFilePath, 'r').read().splitlines() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_gPeNo21azj",
        "outputId": "6f46a8aa-b7b1-4b81-8eb7-2fc5634018f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJRK_EOV1_8U",
        "outputId": "bbb4e52d-ecc9-466a-84fe-f0e2c11b118c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ],
      "source": [
        "# encode chars in the words to integer\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Bd8760V_ok",
        "outputId": "27b13e49-f45d-49d6-f47d-b11e30aae58b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "[0] * 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_L5IWrf2M2i",
        "outputId": "682e8439-20f8-4cfa-ebad-9f7c9dc73e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "olivia\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "ava\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "isabella\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "sophia\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ],
      "source": [
        "# build the dataset\n",
        "\n",
        "'''\n",
        "build the dataset while having the block_size (the number of chars we are going to input at a time) as 3\n",
        "'''\n",
        "block_size = 3 \n",
        "X, Y = [], []\n",
        "for w in words[:5]:\n",
        "  print(w)\n",
        "  context = [0] * block_size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    context = context[1:] + [ix]\n",
        "  \n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X.shape = 32, 3 as the number of inputs are 32 and each have 3 charector input\n",
        "Y.shape = 32, 1 as the number of outcome are 32 and for each respective inputs of 3 charactor there will be one output"
      ],
      "metadata": {
        "id": "qSBgym2lfZEL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shDqtLHNCg9u"
      },
      "source": [
        "As a next step we should encode the dataset X to some sort of format that should be light weight at the same time have the context. \n",
        "\n",
        "If we use the one hot encoding this would work for this particular case as it's only 27 distinct charecter we have in our dataset. but if we take large language models posibily there would be more than a billion distict words makes that diemention to the input set. Therefore we need to scale it down to a smaller diemention without loosing the quality of the prediction. So for that and the following reasons we should scale down the data.\n",
        "\n",
        "*   Sparsity: One-hot encoded vectors are sparse, with only one element being 1 and the rest being 0. This can lead to high memory usage, especially for large vocabularies, as each word requires a vector of the size of the vocabulary.\n",
        "*   Computational complexity: Since one-hot encoded vectors are high-dimensional, matrix multiplications and other operations in the model become computationally expensive. By reducing the dimensionality, you can significantly speed up training and inference.\n",
        "* No semantic information: One-hot encoded vectors don't capture any semantic relationships between words, as they are orthogonal to each other. Word embeddings, on the other hand, are dense vector representations that capture semantic relationships, making it easier for the model to learn and generalize from the data.\n",
        "* Poor generalization: One-hot encoding does not support handling out-of-vocabulary words or handling new words that were not seen during training. Word embeddings can help in this regard by generating embeddings for previously unseen words based on their morphological or contextual similarities to known words.\n",
        "* Difficulty in capturing context: One-hot encoded vectors don't capture context information effectively. Word embeddings, especially when used in combination with more advanced techniques like transformers, can capture long-range dependencies and contextual information, enabling the model to better understand and generate coherent sequences of text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daGO2xXNCU-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b92a561-91ae-43cd-9463-62717c3ef1ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1854, 0.2197], grad_fn=<SqueezeBackward3>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# we can use the matrix multiplication to scale it down. ex (32,27) * (27,2) = (32,2) \n",
        "#Also this is going to be the first layer / input layer of the MLP\n",
        "C = torch.rand(27,2, requires_grad=True)\n",
        "#example with a one hot encoding of 5\n",
        "five_en = torch.nn.functional.one_hot(torch.tensor(5), num_classes=27).float()\n",
        "(five_en @ C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnPA_5tsCZpC",
        "outputId": "5a687606-c847-474c-b605-0e5bfb738343"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1854, 0.2197], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "#apperently this is same as what we are going to get by the integer representation itself|\n",
        "C[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiVsULbXDvjg"
      },
      "source": [
        "So we can dierectly use indexing here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjQfNLzSDroh",
        "outputId": "4fe1cbd7-d9ea-43bb-ee8c-7cb415e95c96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# we can index the whole data set at one go\n",
        "C[X].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is resulting with 32, 3, 2 because we have 32 lines of inputs and each input has 3 character and each character is encoded to 2 diemention instead of 27"
      ],
      "metadata": {
        "id": "Y4JxNLxrlxF6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyHyEN71ElUI"
      },
      "outputs": [],
      "source": [
        "emb = C[X]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But at some point we need to concatinate the 3 character encodings as we need to pass them all together to the inputs to next layer of the model"
      ],
      "metadata": {
        "id": "a-21hKWJm_qR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnoP7FNnFk96",
        "outputId": "07009370-33f5-4982-cd4c-6eb22843e70e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# we can use torch.cat\n",
        "torch.cat([emb[: , 0, :], emb[:, 1, :], emb[:, 2, :]], dim=1).shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use view which is the most efficent way\n",
        "emb.view(32,6).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWKZsFb4noSE",
        "outputId": "f07fb62b-ec9b-4bca-a2b1-075e420b6f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "view() is used to reshape a tensor without altering its underlying data. It returns a new tensor with the specified dimensions that shares the same data with the original tensor. The primary goal of view() is to change the dimensions of a tensor to match the input or output requirements of neural network layers or other operations.\n",
        "\n",
        "torch.cat() is used to concatenate multiple tensors along a specified dimension. This operation combines the input tensors into a single larger tensor, effectively \"stacking\" them along the chosen axis. The input tensors must have the same shape along all dimensions except for the one being concatenated.\n",
        "\n",
        "However in this spesific scenario the data arrangement is going to the same in both the cases as we are effectivly slicing the input. But view is slightly efficent as it's just a reshape operation performed in the same tensor rather than creating a tensor and copying the data to the new diemension in torch.cat"
      ],
      "metadata": {
        "id": "5RvQKxmmsbLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([emb[: , 0, :], emb[:, 1, :], emb[:, 2, :]], dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Txdy3xC_-aY",
        "outputId": "cc9ff8af-76b6-4814-f2be-55a8d0e3582c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.1854, 0.2197],\n",
              "        [0.0608, 0.5287, 0.1854, 0.2197, 0.3247, 0.4423],\n",
              "        [0.1854, 0.2197, 0.3247, 0.4423, 0.3247, 0.4423],\n",
              "        [0.3247, 0.4423, 0.3247, 0.4423, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.9694, 0.9172],\n",
              "        [0.0608, 0.5287, 0.9694, 0.9172, 0.3528, 0.1892],\n",
              "        [0.9694, 0.9172, 0.3528, 0.1892, 0.3750, 0.6086],\n",
              "        [0.3528, 0.1892, 0.3750, 0.6086, 0.6971, 0.9118],\n",
              "        [0.3750, 0.6086, 0.6971, 0.9118, 0.3750, 0.6086],\n",
              "        [0.6971, 0.9118, 0.3750, 0.6086, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.5254, 0.4390, 0.6971, 0.9118],\n",
              "        [0.5254, 0.4390, 0.6971, 0.9118, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.3750, 0.6086],\n",
              "        [0.0608, 0.5287, 0.3750, 0.6086, 0.3703, 0.6709],\n",
              "        [0.3750, 0.6086, 0.3703, 0.6709, 0.5254, 0.4390],\n",
              "        [0.3703, 0.6709, 0.5254, 0.4390, 0.5703, 0.2713],\n",
              "        [0.5254, 0.4390, 0.5703, 0.2713, 0.1854, 0.2197],\n",
              "        [0.5703, 0.2713, 0.1854, 0.2197, 0.3528, 0.1892],\n",
              "        [0.1854, 0.2197, 0.3528, 0.1892, 0.3528, 0.1892],\n",
              "        [0.3528, 0.1892, 0.3528, 0.1892, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.3703, 0.6709],\n",
              "        [0.0608, 0.5287, 0.3703, 0.6709, 0.9694, 0.9172],\n",
              "        [0.3703, 0.6709, 0.9694, 0.9172, 0.5888, 0.7687],\n",
              "        [0.9694, 0.9172, 0.5888, 0.7687, 0.8345, 0.6668],\n",
              "        [0.5888, 0.7687, 0.8345, 0.6668, 0.3750, 0.6086],\n",
              "        [0.8345, 0.6668, 0.3750, 0.6086, 0.5254, 0.4390]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32,6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTMHA3afqdmI",
        "outputId": "6ed59696-e461-4fb4-de34-d1d99d27e3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.1854, 0.2197],\n",
              "        [0.0608, 0.5287, 0.1854, 0.2197, 0.3247, 0.4423],\n",
              "        [0.1854, 0.2197, 0.3247, 0.4423, 0.3247, 0.4423],\n",
              "        [0.3247, 0.4423, 0.3247, 0.4423, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.9694, 0.9172],\n",
              "        [0.0608, 0.5287, 0.9694, 0.9172, 0.3528, 0.1892],\n",
              "        [0.9694, 0.9172, 0.3528, 0.1892, 0.3750, 0.6086],\n",
              "        [0.3528, 0.1892, 0.3750, 0.6086, 0.6971, 0.9118],\n",
              "        [0.3750, 0.6086, 0.6971, 0.9118, 0.3750, 0.6086],\n",
              "        [0.6971, 0.9118, 0.3750, 0.6086, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.5254, 0.4390, 0.6971, 0.9118],\n",
              "        [0.5254, 0.4390, 0.6971, 0.9118, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.3750, 0.6086],\n",
              "        [0.0608, 0.5287, 0.3750, 0.6086, 0.3703, 0.6709],\n",
              "        [0.3750, 0.6086, 0.3703, 0.6709, 0.5254, 0.4390],\n",
              "        [0.3703, 0.6709, 0.5254, 0.4390, 0.5703, 0.2713],\n",
              "        [0.5254, 0.4390, 0.5703, 0.2713, 0.1854, 0.2197],\n",
              "        [0.5703, 0.2713, 0.1854, 0.2197, 0.3528, 0.1892],\n",
              "        [0.1854, 0.2197, 0.3528, 0.1892, 0.3528, 0.1892],\n",
              "        [0.3528, 0.1892, 0.3528, 0.1892, 0.5254, 0.4390],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.0608, 0.5287],\n",
              "        [0.0608, 0.5287, 0.0608, 0.5287, 0.3703, 0.6709],\n",
              "        [0.0608, 0.5287, 0.3703, 0.6709, 0.9694, 0.9172],\n",
              "        [0.3703, 0.6709, 0.9694, 0.9172, 0.5888, 0.7687],\n",
              "        [0.9694, 0.9172, 0.5888, 0.7687, 0.8345, 0.6668],\n",
              "        [0.5888, 0.7687, 0.8345, 0.6668, 0.3750, 0.6086],\n",
              "        [0.8345, 0.6668, 0.3750, 0.6086, 0.5254, 0.4390]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Multilayer Perceptron (MLP) is a type of artificial neural network that can be used for language modeling tasks. The following are some of the hyperparameters that can be adjusted in an MLP for language modeling:\n",
        "\n",
        "1. Architecture: The number of hidden layers and the number of neurons in each layer can be adjusted. Increasing the number of hidden layers and neurons can increase the capacity of the model, but also increase the risk of overfitting.\n",
        "\n",
        "2. Activation Function: The activation function used in each layer can be adjusted. Common choices include ReLU, sigmoid, and tanh.\n",
        "\n",
        "3. Learning Rate: The learning rate determines the step size used to update the model's parameters during training. A too-high learning rate can cause the model to converge slowly or not at all, while a too-low learning rate can cause the model to converge too slowly.\n",
        "\n",
        "4. Momentum: Momentum is a hyperparameter used in gradient descent optimization algorithms to speed up convergence. It adds a fraction of the update vector of the past time step to the current update vector.\n",
        "\n",
        "5. Regularization: Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function. Common choices include L1 and L2 regularization, and dropout.\n",
        "\n",
        "6. Batch Size: The batch size determines the number of samples used in one iteration of training. Larger batch sizes can lead to faster training, but may also require more memory.\n",
        "\n",
        "7. Epochs: The number of training epochs determines how many times the model will see the entire training dataset. More epochs can lead to better model performance, but also increase the risk of overfitting.\n",
        "\n",
        "These are some of the most common hyperparameters that can be adjusted in an MLP for language modeling. The optimal values for these hyperparameters depend on the specific task and dataset, and often require experimentation to determine.\n",
        "\n",
        "These hyperparameter can be optimized mostly by the trial and errors during the training "
      ],
      "metadata": {
        "id": "TBIVk54LusbQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxeWKGiNHcr1"
      },
      "outputs": [],
      "source": [
        "#create hidden layer. having 100 neurons initially and adding tanh as an activation function\n",
        "W1 = torch.randn((6,100), requires_grad=True)\n",
        "b = torch.randn(100, requires_grad=True)\n",
        "out_1 = emb.view(32,6) @ W1 + b\n",
        "out_h = torch.tanh(out_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsAA5gpdJdvZ",
        "outputId": "c0d9e974-06b3-4724-80de-efec7ba9c060"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "out_h.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieM1oPF9Jftl"
      },
      "outputs": [],
      "source": [
        "#create final layer. we are using the softmax for activation function as the expecation to get a probability of each character in 27\n",
        "W2 = torch.randn((100,27) , requires_grad=True)\n",
        "b2 = torch.randn(27, requires_grad=True)\n",
        "logits = out_h @ W2 + b2  \n",
        "#perform softmax\n",
        "counts = torch.exp(logits)\n",
        "counts.shape\n",
        "prob = counts / counts.sum(1, keepdim=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emphasize differences: Exponentiating logits makes the differences between large and small logits more pronounced, causing the softmax function to produce more distinct probabilities. This property is helpful in tasks like classification, where you want the model to be more confident in its predictions.\n",
        "\n",
        "Non-negative probabilities: Exponentiating logits ensures that the resulting probabilities are non-negative, as the exponential function e^x is always positive for any x. This is important because probabilities should always be non-negative by definition.\n",
        "\n",
        "Normalization: After exponentiating logits, they are normalized by dividing each exponentiated logit by the sum of all exponentiated logits. This normalization step ensures that the resulting probabilities sum up to 1, which is a requirement for a valid probability distribution."
      ],
      "metadata": {
        "id": "7Sl3J-2Sw0vk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gavMCZ0vKZFL",
        "outputId": "9d3d9dd5-a8b3-4f68-877a-ae54f2922e37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "prob.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mE10QkTLLeV",
        "outputId": "6b73e238-f656-404a-ac27-00f41df20343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- y actual : e --> 5 \n",
            "---- predicted probabilities :  tensor([9.2058e-09, 2.8377e-08, 1.9253e-11, 1.0980e-12, 1.0549e-10, 4.2874e-05,\n",
            "        1.6895e-10, 2.0007e-07, 1.0367e-07, 5.7103e-07, 4.2138e-07, 2.3852e-13,\n",
            "        1.2725e-03, 2.1721e-10, 9.9866e-01, 1.8841e-06, 1.5907e-05, 2.9767e-10,\n",
            "        1.1804e-10, 1.9446e-11, 4.1211e-09, 3.5602e-06, 3.9668e-06, 1.9299e-06,\n",
            "        1.0988e-07, 3.8290e-12, 5.3616e-13], grad_fn=<SelectBackward0>)\n",
            "---- predicted probability of e 4.287410047254525e-05 \n",
            "---- y actual : m --> 13 \n",
            "---- predicted probabilities :  tensor([9.0467e-08, 3.5002e-07, 7.0688e-10, 3.8022e-13, 5.8197e-09, 8.5859e-04,\n",
            "        4.5188e-10, 3.0516e-05, 2.1899e-06, 8.1055e-07, 3.3353e-07, 2.0459e-11,\n",
            "        1.9545e-02, 3.5852e-09, 9.7930e-01, 7.7021e-06, 8.2741e-06, 1.6000e-09,\n",
            "        6.6088e-11, 1.1564e-10, 2.1660e-07, 8.9642e-06, 2.2314e-04, 1.1213e-05,\n",
            "        2.5890e-08, 2.4274e-11, 1.2802e-09], grad_fn=<SelectBackward0>)\n",
            "---- predicted probability of m 3.585243213422018e-09 \n"
          ]
        }
      ],
      "source": [
        "for i in range(len(Y[:2])):\n",
        "  iy = Y[i].item()\n",
        "  print(f'---- y actual : {itos[iy]} --> {iy} ')\n",
        "  print('---- predicted probabilities : ', prob[i])\n",
        "  print(f'---- predicted probability of {itos[iy]} {prob[i][iy]} ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75aK1OjNQ5wH",
        "outputId": "ee96c7e1-9248-4433-8611-0c1f27e27437"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.2874e-05, 3.5852e-09, 2.0046e-09, 8.1338e-07, 5.2939e-06, 1.8841e-06,\n",
              "        1.7342e-02, 4.5273e-05, 1.6606e-01, 8.8310e-03, 1.6513e-06, 8.6398e-09,\n",
              "        2.8377e-08, 2.5718e-03, 1.2451e-04, 4.0208e-07, 5.7103e-07, 8.5997e-11,\n",
              "        2.6541e-07, 2.9449e-09, 8.7310e-03, 2.3943e-02, 1.2979e-01, 1.0285e-05,\n",
              "        1.8443e-04, 1.9446e-11, 6.0823e-04, 1.4255e-02, 6.4393e-07, 6.0402e-05,\n",
              "        3.9042e-05, 3.7798e-07], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "#get the probability of y act from all the respective 32 input feature set \n",
        "prob[torch.arange(32), Y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj1sVNLFLzQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef6adf7-781c-4da7-908c-6c4e82638b49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11.7678, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "#calculate the log likelyhood which is the loss\n",
        "loss = nll = -prob[torch.arange(32),Y].log().mean() \n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dik3Vt87Qzpy",
        "outputId": "d946d8e2-43ce-4b8d-ba60-328b9314d037"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "#parameter of the model\n",
        "parameters = [C, W1, b, W2, b2]\n",
        "sum(p.nelement() for p in parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross_entropy is a built in feature within the pytorch that calculates the negative log likelyhood againt the Y actual after performing the softmax from the given logits. and as it's inbuilt, this is much more effiecent to use"
      ],
      "metadata": {
        "id": "PMxrPba9yW1B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k__5YzcLUw0v",
        "outputId": "bae7fadf-4afa-4f60-e5ae-09a711b0a37c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(11.7678, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "#there is an internal impl in pytourch which calculates the loss directly\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfT-bmNiciNJ",
        "outputId": "3749a071-a701-40a6-a4fb-01ba6cfa8f51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1434, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "#backpropogate and tune the model\n",
        "for i in range(10):\n",
        "  #forward\n",
        "  emb = C[X]\n",
        "  out_1 = emb.view(-1,6) @ W1 + b\n",
        "  out_h = torch.tanh(out_1)\n",
        "  logits = out_h @ W2 + b2  \n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "  #update\n",
        "  for p in parameters:\n",
        "    p.data += -0.5 * p.grad\n",
        "\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far we have tried with only first five names from the data set. so let's try the same approach with the whole data set"
      ],
      "metadata": {
        "id": "O6mdiMTcB3G3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L049PXX9dXbj"
      },
      "outputs": [],
      "source": [
        "X, Y = [], []\n",
        "\n",
        "for name in words:\n",
        "  context = [0] * 3\n",
        "  for ch in name + '.':\n",
        "    ix = stoi[ch]\n",
        "    Y.append(ix)\n",
        "    X.append(context)\n",
        "    context = context[1:] + [ix]\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we use tensors instead of normal array\n",
        "\n",
        "1. Efficient computation on GPUs: torch.Tensor has built-in support for GPU acceleration, which makes it much faster than standard multidimensional arrays when performing computationally intensive operations. This is especially important in machine learning, where large amounts of data need to be processed quickly.\n",
        "\n",
        "2. Automatic differentiation: torch.Tensor supports automatic differentiation, which is a key feature for training neural networks using techniques like backpropagation. Automatic differentiation allows you to easily calculate gradients of complex functions, which is essential for optimizing model parameters.\n",
        "\n",
        "3. Extensive library support: torch.Tensor is part of the PyTorch library, which has extensive support for machine learning and scientific computing. PyTorch includes many useful tools for building and training neural networks, such as built-in loss functions, optimizers, and activation functions.\n",
        "\n",
        "4. Flexible data types: torch.Tensor supports a wide range of data types, including floating-point numbers, integers, and Boolean values. This flexibility makes it easy to work with different types of data, which is important in many scientific and engineering applications."
      ],
      "metadata": {
        "id": "klrJOApMIyQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,2),requires_grad=True)\n",
        "W1 = torch.randn((6,100), requires_grad=True)\n",
        "b1 = torch.randn(100, requires_grad=True)\n",
        "W2 = torch.randn((100, 27), requires_grad=True)\n",
        "b2 = torch.randn(27, requires_grad=True)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "l72DE7aAJLS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "out_h = (emb.view(-1, 6) @ W1 + b1).tanh()\n",
        "logits = out_h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0BMqdkwNn_A",
        "outputId": "088f3285-b951-4573-a6df-ff790b0fdd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.8664, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  #forward pass\n",
        "  emb = C[X]\n",
        "  logits = ((emb.view(-1,6) @ W1 + b1).tanh()) @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "  print(loss.item())\n",
        "\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  #tune the parameters\n",
        "  for p in parameters:\n",
        "    p.data += -0.1 * p.grad"
      ],
      "metadata": {
        "id": "MI5VgEF-TekU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPjsUmCSU6Fn",
        "outputId": "e8b42588-8e31-4d98-8f93-b31a136fd72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.11656188964844"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this use whole data to forward, backward and update it takes a lot of time. so to address this we use mini batches"
      ],
      "metadata": {
        "id": "sQ4ddznmXGYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generate 32 random indexes of the data set \n",
        "rand_index = torch.randint(0, X.shape[0], (32,))\n",
        "rand_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfetHpFPZiLc",
        "outputId": "c315fcbc-c248-4dd1-f433-aafb2161e071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([145178,  55542, 165105, 155470,  67890, 207320,  87463,  92183, 207983,\n",
              "        167341, 109918, 207072, 198284, 118292, 117272, 196674,  63920,  90477,\n",
              "        153581, 184697, 221058,  20101, 218347, 164952, 208937, 111735, 218765,\n",
              "         84689,  30577, 203178,  61452,  75504])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  #pick up random mini batches of 32 row from the data set in the each iteration\n",
        "  rand_index = torch.randint(0, X.shape[0], (32,))\n",
        "  \n",
        "  #forward pass\n",
        "  emb = C[X[rand_index]]\n",
        "  logits = ((emb.view(-1,6) @ W1 + b1).tanh()) @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Y[rand_index])\n",
        "  print(loss.item())\n",
        "\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  #tune the parameters\n",
        "  for p in parameters:\n",
        "    p.data += -0.1 * p.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2Z8KpKdXGJj",
        "outputId": "965579b0-8b88-4ae0-d005-b34315ee2578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.131815910339355\n",
            "11.153494834899902\n",
            "12.471354484558105\n",
            "8.627363204956055\n",
            "11.52847957611084\n",
            "8.363377571105957\n",
            "9.2767333984375\n",
            "8.009580612182617\n",
            "8.216520309448242\n",
            "8.86539363861084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compare it with the loss from entire data set\n",
        "emb = C[X]\n",
        "out_h = (emb.view(-1, 6) @ W1 + b1).tanh()\n",
        "logits = out_h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGAEDLruaXM_",
        "outputId": "24a18658-a579-4e4b-eb84-8ddef5325923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.8664, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing a good learning rate is a critical step when training a Multilayer Perceptron (MLP) using backpropagation. Here are some methods to determine a better learning rate:\n",
        "--\n",
        "\n",
        "1. Grid Search: Grid search is a simple but effective way to find a good learning rate. In this method, you specify a range of learning rates and train the MLP with each learning rate in the range. You can then evaluate the performance of the model for each learning rate and choose the one that performs best.\n",
        "\n",
        "2. Learning Rate Range Test: The learning rate range test is a more automated way to determine a good learning rate. In this method, you start with a very small learning rate and increase it exponentially while training the model. You can then plot the loss as a function of learning rate and choose the value at which the loss starts to decrease the most rapidly. This method can help you find a good learning rate quickly and without much manual effort.\n",
        "\n",
        "3. Adaptive Learning Rates: Adaptive learning rate methods, such as Adam and Adagrad, adjust the learning rate automatically during training based on the gradients of the loss function. These methods can be more effective than manually tuning the learning rate, as they can adapt to the specific characteristics of the problem being solved.\n",
        "\n",
        "4. Learning Rate Schedules: Learning rate schedules adjust the learning rate over time, typically reducing it as training progresses. Commonly used learning rate schedules include step decay, where the learning rate is reduced by a fixed factor after a certain number of epochs, and exponential decay, where the learning rate is reduced exponentially over time. These methods can help prevent the learning rate from becoming too large during later stages of training, when the gradients are smaller.\n",
        "\n",
        "Overall, choosing a good learning rate can be a bit of an art, and it may require some experimentation to find the best approach for a particular problem. However, these methods provide a good starting point for finding a suitable learning rate for an MLP with backpropagation.\n",
        "\n",
        "on the learning rate range why are we having to increase  exponentially instead of evenly  \n",
        "--\n",
        "When using the learning rate range test to determine a good learning rate, it is often beneficial to increase the learning rate exponentially instead of evenly. The reason for this is that the effect of the learning rate on the loss function can be highly nonlinear, and it can be difficult to identify the optimal learning rate by sampling uniformly over a range of learning rates.\n",
        "\n",
        "Increasing the learning rate exponentially allows us to cover a wider range of learning rates more quickly, while still being able to identify the learning rates that have the greatest impact on the loss function. By starting with a small learning rate and increasing it exponentially, we can quickly move through the range of learning rates and identify the point at which the loss starts to decrease rapidly. This point typically corresponds to a learning rate that is just large enough to make significant progress in reducing the loss, without causing the loss to become unstable.\n",
        "\n",
        "In addition, increasing the learning rate exponentially helps to avoid getting stuck in local minima by allowing the model to explore a wider range of learning rates. By gradually increasing the learning rate, the model can learn more quickly and avoid getting stuck in a suboptimal solution. This can be especially important in deep learning, where the loss function can have many local minima.\n",
        "\n",
        "Overall, using an exponential increase in the learning rate can help to identify a good learning rate more efficiently and effectively than sampling uniformly over a range of learning rates.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xQmjYYpPXDkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# between 0.001 and 1 is a better limit as it seem to be exploding anything beyound this\n",
        "lre = torch.linspace(-3, 0 , 1000)\n",
        "lrs = 10 ** lre\n",
        "lrs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQO-FdxE65q_",
        "outputId": "e7f1e43d-7610-4b4b-a2a8-55dca918b4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011,\n",
              "        0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011,\n",
              "        0.0011, 0.0011, 0.0011, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012,\n",
              "        0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0012, 0.0013, 0.0013, 0.0013,\n",
              "        0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0013, 0.0014,\n",
              "        0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014, 0.0014,\n",
              "        0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015, 0.0015,\n",
              "        0.0015, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016, 0.0016,\n",
              "        0.0016, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017, 0.0017,\n",
              "        0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0018, 0.0019,\n",
              "        0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0019, 0.0020, 0.0020,\n",
              "        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0021, 0.0021, 0.0021, 0.0021,\n",
              "        0.0021, 0.0021, 0.0021, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022, 0.0022,\n",
              "        0.0022, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0023, 0.0024, 0.0024,\n",
              "        0.0024, 0.0024, 0.0024, 0.0024, 0.0025, 0.0025, 0.0025, 0.0025, 0.0025,\n",
              "        0.0025, 0.0026, 0.0026, 0.0026, 0.0026, 0.0026, 0.0027, 0.0027, 0.0027,\n",
              "        0.0027, 0.0027, 0.0027, 0.0028, 0.0028, 0.0028, 0.0028, 0.0028, 0.0029,\n",
              "        0.0029, 0.0029, 0.0029, 0.0029, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
              "        0.0031, 0.0031, 0.0031, 0.0031, 0.0032, 0.0032, 0.0032, 0.0032, 0.0032,\n",
              "        0.0033, 0.0033, 0.0033, 0.0033, 0.0034, 0.0034, 0.0034, 0.0034, 0.0034,\n",
              "        0.0035, 0.0035, 0.0035, 0.0035, 0.0036, 0.0036, 0.0036, 0.0036, 0.0037,\n",
              "        0.0037, 0.0037, 0.0037, 0.0038, 0.0038, 0.0038, 0.0039, 0.0039, 0.0039,\n",
              "        0.0039, 0.0040, 0.0040, 0.0040, 0.0040, 0.0041, 0.0041, 0.0041, 0.0042,\n",
              "        0.0042, 0.0042, 0.0042, 0.0043, 0.0043, 0.0043, 0.0044, 0.0044, 0.0044,\n",
              "        0.0045, 0.0045, 0.0045, 0.0045, 0.0046, 0.0046, 0.0046, 0.0047, 0.0047,\n",
              "        0.0047, 0.0048, 0.0048, 0.0048, 0.0049, 0.0049, 0.0049, 0.0050, 0.0050,\n",
              "        0.0050, 0.0051, 0.0051, 0.0051, 0.0052, 0.0052, 0.0053, 0.0053, 0.0053,\n",
              "        0.0054, 0.0054, 0.0054, 0.0055, 0.0055, 0.0056, 0.0056, 0.0056, 0.0057,\n",
              "        0.0057, 0.0058, 0.0058, 0.0058, 0.0059, 0.0059, 0.0060, 0.0060, 0.0060,\n",
              "        0.0061, 0.0061, 0.0062, 0.0062, 0.0062, 0.0063, 0.0063, 0.0064, 0.0064,\n",
              "        0.0065, 0.0065, 0.0066, 0.0066, 0.0067, 0.0067, 0.0067, 0.0068, 0.0068,\n",
              "        0.0069, 0.0069, 0.0070, 0.0070, 0.0071, 0.0071, 0.0072, 0.0072, 0.0073,\n",
              "        0.0073, 0.0074, 0.0074, 0.0075, 0.0075, 0.0076, 0.0076, 0.0077, 0.0077,\n",
              "        0.0078, 0.0079, 0.0079, 0.0080, 0.0080, 0.0081, 0.0081, 0.0082, 0.0082,\n",
              "        0.0083, 0.0084, 0.0084, 0.0085, 0.0085, 0.0086, 0.0086, 0.0087, 0.0088,\n",
              "        0.0088, 0.0089, 0.0090, 0.0090, 0.0091, 0.0091, 0.0092, 0.0093, 0.0093,\n",
              "        0.0094, 0.0095, 0.0095, 0.0096, 0.0097, 0.0097, 0.0098, 0.0099, 0.0099,\n",
              "        0.0100, 0.0101, 0.0101, 0.0102, 0.0103, 0.0104, 0.0104, 0.0105, 0.0106,\n",
              "        0.0106, 0.0107, 0.0108, 0.0109, 0.0109, 0.0110, 0.0111, 0.0112, 0.0112,\n",
              "        0.0113, 0.0114, 0.0115, 0.0116, 0.0116, 0.0117, 0.0118, 0.0119, 0.0120,\n",
              "        0.0121, 0.0121, 0.0122, 0.0123, 0.0124, 0.0125, 0.0126, 0.0127, 0.0127,\n",
              "        0.0128, 0.0129, 0.0130, 0.0131, 0.0132, 0.0133, 0.0134, 0.0135, 0.0136,\n",
              "        0.0137, 0.0137, 0.0138, 0.0139, 0.0140, 0.0141, 0.0142, 0.0143, 0.0144,\n",
              "        0.0145, 0.0146, 0.0147, 0.0148, 0.0149, 0.0150, 0.0151, 0.0152, 0.0154,\n",
              "        0.0155, 0.0156, 0.0157, 0.0158, 0.0159, 0.0160, 0.0161, 0.0162, 0.0163,\n",
              "        0.0165, 0.0166, 0.0167, 0.0168, 0.0169, 0.0170, 0.0171, 0.0173, 0.0174,\n",
              "        0.0175, 0.0176, 0.0178, 0.0179, 0.0180, 0.0181, 0.0182, 0.0184, 0.0185,\n",
              "        0.0186, 0.0188, 0.0189, 0.0190, 0.0192, 0.0193, 0.0194, 0.0196, 0.0197,\n",
              "        0.0198, 0.0200, 0.0201, 0.0202, 0.0204, 0.0205, 0.0207, 0.0208, 0.0210,\n",
              "        0.0211, 0.0212, 0.0214, 0.0215, 0.0217, 0.0218, 0.0220, 0.0221, 0.0223,\n",
              "        0.0225, 0.0226, 0.0228, 0.0229, 0.0231, 0.0232, 0.0234, 0.0236, 0.0237,\n",
              "        0.0239, 0.0241, 0.0242, 0.0244, 0.0246, 0.0247, 0.0249, 0.0251, 0.0253,\n",
              "        0.0254, 0.0256, 0.0258, 0.0260, 0.0261, 0.0263, 0.0265, 0.0267, 0.0269,\n",
              "        0.0271, 0.0273, 0.0274, 0.0276, 0.0278, 0.0280, 0.0282, 0.0284, 0.0286,\n",
              "        0.0288, 0.0290, 0.0292, 0.0294, 0.0296, 0.0298, 0.0300, 0.0302, 0.0304,\n",
              "        0.0307, 0.0309, 0.0311, 0.0313, 0.0315, 0.0317, 0.0320, 0.0322, 0.0324,\n",
              "        0.0326, 0.0328, 0.0331, 0.0333, 0.0335, 0.0338, 0.0340, 0.0342, 0.0345,\n",
              "        0.0347, 0.0350, 0.0352, 0.0354, 0.0357, 0.0359, 0.0362, 0.0364, 0.0367,\n",
              "        0.0369, 0.0372, 0.0375, 0.0377, 0.0380, 0.0382, 0.0385, 0.0388, 0.0390,\n",
              "        0.0393, 0.0396, 0.0399, 0.0401, 0.0404, 0.0407, 0.0410, 0.0413, 0.0416,\n",
              "        0.0418, 0.0421, 0.0424, 0.0427, 0.0430, 0.0433, 0.0436, 0.0439, 0.0442,\n",
              "        0.0445, 0.0448, 0.0451, 0.0455, 0.0458, 0.0461, 0.0464, 0.0467, 0.0471,\n",
              "        0.0474, 0.0477, 0.0480, 0.0484, 0.0487, 0.0491, 0.0494, 0.0497, 0.0501,\n",
              "        0.0504, 0.0508, 0.0511, 0.0515, 0.0518, 0.0522, 0.0526, 0.0529, 0.0533,\n",
              "        0.0537, 0.0540, 0.0544, 0.0548, 0.0552, 0.0556, 0.0559, 0.0563, 0.0567,\n",
              "        0.0571, 0.0575, 0.0579, 0.0583, 0.0587, 0.0591, 0.0595, 0.0599, 0.0604,\n",
              "        0.0608, 0.0612, 0.0616, 0.0621, 0.0625, 0.0629, 0.0634, 0.0638, 0.0642,\n",
              "        0.0647, 0.0651, 0.0656, 0.0660, 0.0665, 0.0670, 0.0674, 0.0679, 0.0684,\n",
              "        0.0688, 0.0693, 0.0698, 0.0703, 0.0708, 0.0713, 0.0718, 0.0723, 0.0728,\n",
              "        0.0733, 0.0738, 0.0743, 0.0748, 0.0753, 0.0758, 0.0764, 0.0769, 0.0774,\n",
              "        0.0780, 0.0785, 0.0790, 0.0796, 0.0802, 0.0807, 0.0813, 0.0818, 0.0824,\n",
              "        0.0830, 0.0835, 0.0841, 0.0847, 0.0853, 0.0859, 0.0865, 0.0871, 0.0877,\n",
              "        0.0883, 0.0889, 0.0895, 0.0901, 0.0908, 0.0914, 0.0920, 0.0927, 0.0933,\n",
              "        0.0940, 0.0946, 0.0953, 0.0959, 0.0966, 0.0973, 0.0979, 0.0986, 0.0993,\n",
              "        0.1000, 0.1007, 0.1014, 0.1021, 0.1028, 0.1035, 0.1042, 0.1050, 0.1057,\n",
              "        0.1064, 0.1072, 0.1079, 0.1087, 0.1094, 0.1102, 0.1109, 0.1117, 0.1125,\n",
              "        0.1133, 0.1140, 0.1148, 0.1156, 0.1164, 0.1172, 0.1181, 0.1189, 0.1197,\n",
              "        0.1205, 0.1214, 0.1222, 0.1231, 0.1239, 0.1248, 0.1256, 0.1265, 0.1274,\n",
              "        0.1283, 0.1292, 0.1301, 0.1310, 0.1319, 0.1328, 0.1337, 0.1346, 0.1356,\n",
              "        0.1365, 0.1374, 0.1384, 0.1394, 0.1403, 0.1413, 0.1423, 0.1433, 0.1443,\n",
              "        0.1453, 0.1463, 0.1473, 0.1483, 0.1493, 0.1504, 0.1514, 0.1525, 0.1535,\n",
              "        0.1546, 0.1557, 0.1567, 0.1578, 0.1589, 0.1600, 0.1611, 0.1623, 0.1634,\n",
              "        0.1645, 0.1657, 0.1668, 0.1680, 0.1691, 0.1703, 0.1715, 0.1727, 0.1739,\n",
              "        0.1751, 0.1763, 0.1775, 0.1788, 0.1800, 0.1812, 0.1825, 0.1838, 0.1850,\n",
              "        0.1863, 0.1876, 0.1889, 0.1902, 0.1916, 0.1929, 0.1942, 0.1956, 0.1969,\n",
              "        0.1983, 0.1997, 0.2010, 0.2024, 0.2038, 0.2053, 0.2067, 0.2081, 0.2096,\n",
              "        0.2110, 0.2125, 0.2140, 0.2154, 0.2169, 0.2184, 0.2200, 0.2215, 0.2230,\n",
              "        0.2246, 0.2261, 0.2277, 0.2293, 0.2309, 0.2325, 0.2341, 0.2357, 0.2373,\n",
              "        0.2390, 0.2406, 0.2423, 0.2440, 0.2457, 0.2474, 0.2491, 0.2508, 0.2526,\n",
              "        0.2543, 0.2561, 0.2579, 0.2597, 0.2615, 0.2633, 0.2651, 0.2669, 0.2688,\n",
              "        0.2707, 0.2725, 0.2744, 0.2763, 0.2783, 0.2802, 0.2821, 0.2841, 0.2861,\n",
              "        0.2880, 0.2900, 0.2921, 0.2941, 0.2961, 0.2982, 0.3002, 0.3023, 0.3044,\n",
              "        0.3065, 0.3087, 0.3108, 0.3130, 0.3151, 0.3173, 0.3195, 0.3217, 0.3240,\n",
              "        0.3262, 0.3285, 0.3308, 0.3331, 0.3354, 0.3377, 0.3400, 0.3424, 0.3448,\n",
              "        0.3472, 0.3496, 0.3520, 0.3544, 0.3569, 0.3594, 0.3619, 0.3644, 0.3669,\n",
              "        0.3695, 0.3720, 0.3746, 0.3772, 0.3798, 0.3825, 0.3851, 0.3878, 0.3905,\n",
              "        0.3932, 0.3959, 0.3987, 0.4014, 0.4042, 0.4070, 0.4098, 0.4127, 0.4155,\n",
              "        0.4184, 0.4213, 0.4243, 0.4272, 0.4302, 0.4331, 0.4362, 0.4392, 0.4422,\n",
              "        0.4453, 0.4484, 0.4515, 0.4546, 0.4578, 0.4610, 0.4642, 0.4674, 0.4706,\n",
              "        0.4739, 0.4772, 0.4805, 0.4838, 0.4872, 0.4906, 0.4940, 0.4974, 0.5008,\n",
              "        0.5043, 0.5078, 0.5113, 0.5149, 0.5185, 0.5221, 0.5257, 0.5293, 0.5330,\n",
              "        0.5367, 0.5404, 0.5442, 0.5479, 0.5517, 0.5556, 0.5594, 0.5633, 0.5672,\n",
              "        0.5712, 0.5751, 0.5791, 0.5831, 0.5872, 0.5913, 0.5954, 0.5995, 0.6036,\n",
              "        0.6078, 0.6120, 0.6163, 0.6206, 0.6249, 0.6292, 0.6336, 0.6380, 0.6424,\n",
              "        0.6469, 0.6513, 0.6559, 0.6604, 0.6650, 0.6696, 0.6743, 0.6789, 0.6837,\n",
              "        0.6884, 0.6932, 0.6980, 0.7028, 0.7077, 0.7126, 0.7176, 0.7225, 0.7275,\n",
              "        0.7326, 0.7377, 0.7428, 0.7480, 0.7531, 0.7584, 0.7636, 0.7689, 0.7743,\n",
              "        0.7796, 0.7850, 0.7905, 0.7960, 0.8015, 0.8071, 0.8127, 0.8183, 0.8240,\n",
              "        0.8297, 0.8355, 0.8412, 0.8471, 0.8530, 0.8589, 0.8648, 0.8708, 0.8769,\n",
              "        0.8830, 0.8891, 0.8953, 0.9015, 0.9077, 0.9140, 0.9204, 0.9268, 0.9332,\n",
              "        0.9397, 0.9462, 0.9528, 0.9594, 0.9660, 0.9727, 0.9795, 0.9863, 0.9931,\n",
              "        1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stepi = []\n",
        "lrei = []\n",
        "lossi = []\n",
        "\n",
        "for i in range(1000):\n",
        "  #pick up random mini batches of 32 row from the data set in the each iteration\n",
        "  rand_index = torch.randint(0, X.shape[0], (32,))\n",
        "\n",
        "  #forward pass\n",
        "  emb = C[X[rand_index]]\n",
        "  logits = ((emb.view(-1,6) @ W1 + b1).tanh()) @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Y[rand_index])\n",
        "\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = lrs[i]\n",
        "  #tune the parameters\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  stepi.append(i)\n",
        "  lrei.append(lr)\n",
        "  lossi.append(loss.item())"
      ],
      "metadata": {
        "id": "jeq2uC6ukYAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lrei, lossi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6QHvYE6Co7ii",
        "outputId": "19be65f2-df7c-4c97-ce7c-0508ed3db1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f56cd8ae4c0>]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So based on these we can see it's very stable when it's around -0.1. therefore it can be used as the learning rate"
      ],
      "metadata": {
        "id": "nnUaTK1PaisC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(stepi, lossi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Nwe_ndF-H_OU",
        "outputId": "6e646890-fc18-4b09-d440-5933c898197b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f56cd6c84f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X] \n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7B2LyOP7jRb",
        "outputId": "c28a8d6f-bcea-40f0-bbcd-acff60482c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.8614, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
        "for i in range(C.shape[0]):\n",
        "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
        "plt.grid('minor')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "K2gqxyR1-WTV",
        "outputId": "5301f144-db9c-4f39-e951-7a8e20219c99"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAHSCAYAAAAuWvi9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAA470lEQVR4nO3de3hV9YH/+883OxdiggQvhDRQUUStGhGNQOulQZ0q/DoVW2cGp7XeKiOjtZfpObUPnulxzsOv7Zyn005PHTrYUmk709jR0jIWxlbaeC0IKhDAAsFLQ+SiQoCEkOzL9/yx9w7ZO2uHnWTfvnu9X8+Th+y91spa3+xFPmut781YawUAAApbSb4PAAAAnByBDQCAAwhsAAAcQGADAOAAAhsAAAcQ2AAAOKA03weQyhlnnGGnTJmSt/13d3erqqoqb/vPBz+WWfJnuSmzf/ix3C6X+ZVXXnnPWnum17KCDewpU6Zo48aNedt/S0uLmpqa8rb/fPBjmSV/lpsy+4cfy+1ymY0xb6daxiNxAAAcQGADAOAAAhsAAAcQ2AAAOIDABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHEBgAwDgAAIbaQuFIzpyPKhwxOb7UADAdwp2LHEUht5QWKtb92ppy27tOtCl0hKjUMTqvAnVurdpquY11KmiNJDvwwSAokdgI6VN7Z26Y/nLCoYj6u4LS5KC4ejd9Y79XXpo5VY9vGq7Vtw1U9Mn1+TxSAGg+PFIHJ42t3fq1mXr1NkT7A/rZN19YXX2BLVg2Tptbu/M7QECgM8Q2BikNxTW7ctfVk/QO6iT9QSj6/eG0lsfADB8PBLHIKtb9yoYjiS8d9+cc/Wpy+r1fnef9nb2qLXjiB59/o3+5cFwRGta92n+jPpcHy4A+AJ32BhkacvuhMfgF9efqr+cXqd533ted/54gy6ZVDNom+6+sJa2tOXwKAHAX0Yd2MaYycaYPxhjthtjthljvuCxjjHGfM8Y02aM2WKMuWy0+0V2hCNWuw50Jbw3c8ppenrbfh0PRtTVG9Izr+/33HbngS66fAFAlmTiDjsk6R+stRdKmi3pPmPMhUnrzJU0Lfa1UNLSDOwXWdDdF1JpiRnRtqUlRt19oQwfEQBAykBgW2v3WmtfjX1/VNLrkpIrMm+S9BMbtU5SjTGmbrT7RuZVlZcqlHSXvP7Ng/rYhbWqKC1RVXlA132o1nPbUMSqqpxmEQCQDRn962qMmSJphqT1SYvqJbUPeL0n9t7eTO4foxcoMZo2oVo79594LL7tnSN6asterfnC1Xq/u09b9nR6bnvehGoFRnh3DgAYmrE2M3WOxphqSc9KWmKt/WXSsqckfdNa+0Ls9VpJX7XWbkxab6Gij8xVW1t7eXNzc0aObSS6urpUXV2dt/3nQ7zMnT1BdRzqUSTFuTGz4XwFQyG99vru/vdKjFH9+ErVVJbl6nAzxs+ftZ/4scySP8vtcpnnzJnzirW20WtZRu6wjTFlkp6U9B/JYR3TIWnygNeTYu8lsNYuk7RMkhobG21TU1MmDm9EWlpalM/950O8zL2hsGYtWavOnqDnel+sLVF3b0CPtp44fWoqy7R+8bVODlPq58/aT/xYZsmf5S7WMmeilbiR9CNJr1tr/yXFaqskfTbWWny2pMPWWh6HF6iK0oBW3DVTlWXe4fvdZ3Yl9MGuLIuu72JYA4ArMtFK/EpJt0m61hizKfY1zxhzrzHm3tg6qyW9IalN0qOS/j4D+0UWTZ9co+aFs1VTWaaqcu8grioPqKayTM0LZzOWOABk2agficfqpYdsaWSjFeX3jXZfyK3pk2u0fvF1WtO6T0tb2rQzYbausVrUNFVzGyZyZw0AOUAfHAypojSg+TPqNX9GvcIRq+6+kKrKS2kNDgA5RmAjbYESo1PHuNcKHACKAWOJAwDgAAIbAAAHENgAADiAwAYAwAEENgAADiCwAQBwAIENAIADCGwAABxAYAMA4AACGwAABxDYAAA4gMAGAMABBDYAAA4gsAEAcACBDQCAAwhsAAAcQGADAOAAAhsAAAcQ2AAAOIDABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHEBgAwDgAAIbAAAHENgAADiAwAYAwAEENgAADiCwAQBwAIENAIADCGwAABxAYAMA4AACGwAABxDYAAA4gMAGAMABBDYAAA4gsAEAcACBDQCAAwhsAAAcQGADAOAAAhsAAAcQ2AAAOIDABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHEBgAwDgAAIbAAAHENgAADiAwAYAwAEENgAADshIYBtjlhtjDhhjtqZY3mSMOWyM2RT7+sdM7BcAAL8ozdDPeUzS9yX9ZIh1nrfWfjxD+wMAwFcycodtrX1O0sFM/CwAADBYLuuwP2yM2WyMWWOMuSiH+wUAwHnGWpuZH2TMFElPWWsv9lh2qqSItbbLGDNP0r9aa6d5rLdQ0kJJqq2tvby5uTkjxzYSXV1dqq6uztv+88GPZZb8WW7K7B9+LLfLZZ4zZ84r1tpGr2U5CWyPdd+S1GitfS/VOo2NjXbjxo0ZObaRaGlpUVNTU972nw9+LLPkz3JTZv/wY7ldLrMxJmVg5+SRuDFmojHGxL6fGdvv+7nYNwAAxSAjrcSNMT+X1CTpDGPMHklfl1QmSdbaH0i6RdIiY0xIUo+kBTZTt/YAAPhARgLbWnvrSZZ/X9FuXwAAYAQY6QwAAAcQ2AAAOIDABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHEBgAwDgAAIbAAAHENgAADiAwAYAwAEENgAADiCwAQBwAIENAIADCGwAABxAYAMA4AACGwAABxDYAAA4gMAGAMABBDYAAA4gsAEAcACBDQCAAwhsAAAcQGADAOAAAhsAAAcQ2AAAOIDABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHEBgAwDgAAIbAAAHENgAADiAwAYAwAEENgAADiCwAQBwAIENAIADCGwAABxAYAMA4AACGwAABxDYAAA4gMAGAMABBDYAAA4gsAEAcACBDQCAAwhsAAAcQGADAOAAAhsAAAcQ2AAAOIDABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHJCRwDbGLDfGHDDGbE2x3BhjvmeMaTPGbDHGXJaJ/QIA4BeZusN+TNKNQyyfK2la7GuhpKUZ2i8AAL6QkcC21j4n6eAQq9wk6Sc2ap2kGmNMXSb2DQCAHxhrbWZ+kDFTJD1lrb3YY9lTkr5prX0h9nqtpK9aazcmrbdQ0Ttw1dbWXt7c3JyRYxuJrq4uVVdX523/+eDHMkv+LDdl9g8/ltvlMs+ZM+cVa22j17LSXB/MUKy1yyQtk6TGxkbb1NSUt2NpaWlRPvefD34ss+TPclNm//BjuYu1zLlqJd4hafKA15Ni7wEAgDTkKrBXSfpsrLX4bEmHrbV7c7RvAACcl5FH4saYn0tqknSGMWaPpK9LKpMka+0PJK2WNE9Sm6Rjku7MxH4BAPCLjAS2tfbWkyy3ku7LxL4AAPAjRjoDAMABBDYAAA4gsAEAcACBDQCAAwhsAAAcQGADAOAAAhsAAAcQ2AAAOIDABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHEBgAwDgAAIbAAAHENgAADiAwAYAwAEENgAADiCwAQBwAIENAIADCGwAABxAYAMA4AACGwAABxDYAAA4gMAGAMABBDYAAA4gsAEAcACBDQCAAwhsAAAcQGADAOAAAhsAAAcQ2AAAOIDABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHEBgAwDgAAIbAAAHENgAADiAwAYAwAEENoCsCIUjOnI8qHDE5vtQgKJQmu8DAFA8ekNhrW7dq6Utu7XrQJdKS4xCEavzJlTr3qapmtdQp4rSQL4PE3ASgQ0gIza1d+qO5S8rGI6ouy8sSQqGo3fXO/Z36aGVW/Xwqu1acddMTZ9ck8cjBdzEI3EAo7a5vVO3Llunzp5gf1gn6+4Lq7MnqAXL1mlze2duDxAoAgQ2gFHpDYV1+/KX1RP0DupkPcHo+r2h9NYHEEVgAxiV1a17FQxHhrVNMBzRmtZ9WToioDhRhw1gVJa27PZ8DD7/0nrdceUUlQeMNrV36qFfbVW8wXh3X1hLW9o0f0Z9jo8WcBd32ABGLByx2nWga9D7U8+s1sen1+mWpS9p3vdeUDiiQeG880AXXb6AYeAOG8CIdfeFVFpi+luDx1157ulqqB+nVfdfKUmqKAvo/e7ehHVKS4y6+0I6dUxZzo4XcBmBDWDEqspLFfK4SzbG6MlX9uifn96RcttQxKqqnD9BQLp4JA5gxAIlRtMmVA96/8W29zS3oU6nV5VLksZVlqm+pjJhnfMmVCtQYnJynEAxILABjMqipqmqKk8cvaztQJe+/dsd+undM7XmC1frZ3fP0oSxFf3Lq8oDWtR0bq4PFXAaz6MAjMq8hjo9vGq7pMSW4k9t2auntuz13KYsUKK5DRNzcHRA8eAOG8CoVJQGtOKumaosS2+M8Mqy6PqMKQ4MT0YC2xhzozFmhzGmzRjzoMfyO4wx7xpjNsW+PpeJ/QIoDNMn16h54WzVVJYNejweV1UeUE1lmZoXzmYscWAERv1I3BgTkPSIpL+QtEfSBmPMKmvt9qRVH7fW3j/a/QEoTNMn12j94uu0pnWflra0aWfCbF1jtahpquY2TOTOGhihTNRhz5TUZq19Q5KMMc2SbpKUHNgAilxFaUDzZ9Rr/ox6hSNW3X0hVZWX0hocyABj7ehGGjLG3CLpRmvt52Kvb5M0a+DdtDHmDknfkPSupJ2SvmStbff4WQslLZSk2tray5ubm0d1bKPR1dWl6urB3VWKmR/LLPmz3JTZP/xYbpfLPGfOnFestY1ey3LVSvy/Jf3cWttrjPk7SSskXZu8krV2maRlktTY2GibmppydHiDtbS0KJ/7zwc/llnyZ7kps3/4sdzFWuZMNDrrkDR5wOtJsff6WWvft9bGxyX8oaTLM7BfAAB8IxOBvUHSNGPM2caYckkLJK0auIIxpm7Ay09Iej0D+wUAwDdG/UjcWhsyxtwv6WlJAUnLrbXbjDH/JGmjtXaVpAeMMZ+QFJJ0UNIdo90vAAB+kpE6bGvtakmrk977xwHff03S1zKxLwAA/IiRzgAAcACBDQCAAwhsAAAcQGADAOAAAhsAAAcQ2AAAOIDABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHEBgAwDgAAIbAAAHENgAADiAwAYAwAEEdoEIhSM6cjyocMTm+1AAAAWoNN8H4Ge9obBWt+7V0pbd2nWgS6UlRqGI1XkTqnVv01TNa6hTRWkg34cJwEMoHNGxYFhV5aUKlJh8Hw58gMDOk03tnbpj+csKhiPq7gtLkoLh6N31jv1demjlVj28artW3DVT0yfX5PFIAcRxkY184pF4Hmxu79Sty9apsyfYH9bJuvvC6uwJasGyddrc3pnbAwQwyKb2Ts1aslYPrdyqnfu7ZG30ItvaExfZs5as5f8rsobAzrHeUFi3L39ZPUHvoE7WE4yu3xtKb30AmZfqIvvJRR/p/56LbGQbgZ1jq1v3KhiODGubYDiiNa37snREAIYy1EX2p5a+NOg9LrKRLQR2ji1t2Z3yMXgq3X1hLW1py9IRARjKUBfZ2x6+wfN9LrKRDQR2DoUjVrsOdI1o250HuujyBeQBF9koFAR2DnX3hVQ6wu4fpSVG3X2hDB8RgKFwkY1CQmDnUFV5qUIj/A8cilhVldMLbyQYlAYjxUU2CgkJkEOBEqNpE6q1c//gK/Yf33GFvvrkFh042uu57XkTqhmcYRjoL4tM4CIbhYQ77Bxb1DRVVeWDg+LOxzakDOuq8oAWNZ2b7UMrGvSXRabEL7JHgotsZBqBnWPzGupUFhjer70sUKK5DROzdETFhUFpkGmpLrIl6aKvP+35PhfZyAYCO8cqSgNacddMVZal9zi2siy6Po9vT26kg9JQs42hcJGNQkFg58H0yTVqXjhbNZVlKa/cq8oDqqksU/PC2YwlnqZU/WWX3Xa5/vv+q/TbL12jW2dOTlgWDEd0uCeYq0OEg7jIRqGgRUSeTJ9co/WLr9Oa1n1a2tKmnQkNo8ZqUdNUzW2YyH/6YUjVX/b/eGKLDvcEVVFaolX3X6U1W/ep81g0pLv7wnr3KC15MbT4RfbtSRP2DFRVHlBZoIQJe5A1BHYeVZQGNH9GvebPqFc4YtXdF2KqvhEaqr/snVdO0Q0XRR9P1tWM0dmnV+m1Y539y48HwwpHLL93DImLbOQbgV0gAiVGp44py/dhOCveXzY+RWnc7HNO05XnnqGb/+1FHQ9G1LxwtirKEmuCjIn2l+X3j5PhIhv5RGCjKKTqLzt2TJkO9wR1PBjR1DOrNMPjUaW19JfF8HGRjVyj0RmKQqr+ss/ueFelJUbPfPmj+uqNF+g1j25cY8oC3CEBKHjcVqBoLGqaqodWbk1oENQXjuiOH29IuU1VeUBnji38OsdQOKJjwTCPXwEfI7BRNOY11OnhVdslpT+zUlmgROMqC/OxJsOrAhiIR+IoGiPtL1uI96sMrwogGYGNolIMg9IwvCoALwQ2ik68v+ySmxt0fm21jJHKAkbGSOfXjtWSmxu0fvF1BRnWIx1etTeUfjVAIWMqVCA16rBRlFztL5tqeNWhBMMRrWndp/kz6rN0VNlFXT2QHgIbRc+l/rKphle9+6qz9deN0XHQH9/wZy1/8a3+Zd19YS1taXMysDe1d+qOpOE+44PfxOvqH161neE+AfFIHCgYqYZXvbj+VP1V4yTNf+RF3fxvL2rBzA/qog+cmrDOzgNdzj1Gpq4eGB4CGygQ8eFVk10x5TQ9vW2/eoJhHesL63+27tMVU05LWKe0JDq8qiv8XlcPjASBDRSIVMOrpiMUcWt4Va+6+knjK/X0F6/pf33P1efoi9dP638dr6sH/IrABgpEquFVX37zoD52Ya3GlJWosiygGy6aqA1vHUxY57wJ1QXfoG6gVHX1Q4nX1QN+RWADBWRR09RB/ce3vXNET7yyR7++7yr96r4r9fiGP2vbO0f6l1eVB7So6dxcH+qIDTUV6sm4WFcPZIo7z9AAH0g1vOqPXnhTP3rhTc9tygIlmtswMQdHlxmppkINha0GPiRIngZVOlFX70qrfyCTuMMGCshIh1d1qZ9yqrr697p6dXp1hWpOKVN5oETXXTBh0Dqu1dUDmURgAwWmGIZXHUqquvpQxOp7a3fp1/ddqZ9+bqZ2vzv4sblrdfVAJnGpChSg+PCqa1r3aWlLm3YmjAA2Vouapmpuw0Sn7qwH8poKVZIee+ktPfbSW57buFZXD2QagQ0UKFeHV03HSKdCdamuHsg0HokDDogPr1oMYS35o64eyDQCG0BeFHtdPZBpGQlsY8yNxpgdxpg2Y8yDHssrjDGPx5avN8ZMycR+AbjN5alQiwnTmrph1HXYxpiApEck/YWkPZI2GGNWWWu3D1jtbkmHrLXnGmMWSPqWpL8Z7b4BuK+Y6+oLGdOauicTd9gzJbVZa9+w1vZJapZ0U9I6N0laEfv+CUnXGWP43wggQbHV1ReqTe2dmrVkrR5auVU793fJ2ui0ptaemNZ01pK1zJBWYDIR2PWS2ge83hN7z3Mda21I0mFJp2dg3wCAYUie1jR50hWJaU0LVUF16zLGLJS0UJJqa2vV0tKSt2Pp6urK6/7zwY9llvxZbsrsHwPLbSW9vveI/v6CE3XVY6tCOmOM1T80eE3PGtKLLzyng3WnyqVnHsX6WWcisDskTR7welLsPa919hhjSiWNk/R+8g+y1i6TtEySGhsbbVNTUwYOb2RaWlqUz/3ngx/LLPmz3JTZPwaWe+Vre/TI7xMHrJk0vlRXf6REky9s1MX147Rz/1F9+RebdDwYnf60qjygJRdM0/wZyQ9OC1exftaZeCS+QdI0Y8zZxphySQskrUpaZ5Wk22Pf3yLp99ZamiMCQA6lmtZ06oRq/XTd27r+X55VV29It82e0r+MaU0Lx6gDO1Ynfb+kpyW9LukX1tptxph/MsZ8IrbajySdboxpk/RlSYO6fgEAsmeoaU07Onv0ytuHJEkrX+vQFVPGJyxnWtPCkJE6bGvtakmrk977xwHfH5f0V5nYFwBg+FJNaypJyQ88k9dgWtPCwEhnAOADqaY1laRJ40/RZR+skSTddOkHtOGtgwnLmda0MBDYAOADqaY1laTdB7p024en6Jkvf1TjKsv0s3VvJyxnWtPCwCUTAPiE17Smew716Lp/eTblNkxrWji4wwYAn5jXUKeywPD+7DOtaeEgsAHAJ5jW1G0ENgD4CNOauos6bADwmfi0pmta92lpS5t2JszWNVaLmqZqbsNE7qwLDIENAD7EtKbu4ZE4AKQhFI7oyPFgUY74xbSmbuAOGwBS6A2Ftbp1r5a27NauhMfG1bq3aarmNdTx2Bg5Q2ADgIdN7Z26Y/nLCoYj/f2W48N67tjfpYdWbtXDq7ZrxV0zaZiFnOCROAAk2dzeqVuXrVNnT9BzdispOotVZ09QC5at0+b2ztweIHyJwAZQ1OJ1z+nqDYV1+/KX1RP0DupkPcHo+r2h9NYHRopH4gCKjlfd8wMXBvWN7zx70rrn1a17FQxHBr3/+WvP1fwZ9TrY3ae9nT1q7TiiR59/Q5IUDEe0pnWf5s+oz2q5ClkoHNGxYJiW5llEYAMoKqOte17asnvQY/BLJo3T3Isnat6/Pq/SEqOnHrharR1H+pd394W1tKXNd4FNo7zc4pE4gKIx2rrncMRq14GuQds0njVev9u+X72h6EXA2tf3D1pn54Guouzylcqm9k7NWrJWD63cqp37u2Rt9MLI2hMXRrOWrKV+P4MIbABFIVXd8x0fiU4b+bGPXJbwvlfdc3dfSKUjfJxbWmLU3Rca0bauoVFefhDYAIpCqrrn22afpc/8cL1++9Krg5bF657jqspLFfK4S9749iFd96FaVZSW6JTygK69YMKgdUIRq6ry4q9lpFFe/hT/2QXAF7zqnpfMv1iTTztFj911hd7teFtq/XPC8uS650CJ0bQJ1dq5P/Gx+JY9h/XM6/u15gtX672uPu3Yf1RHk1qenzeh2heNrbwujCaNr9SKO2eqteOwLq4fp537j+rLv9ik48HoejTKywzusAE4L1Xd8+JfbdWBo8d167J12vSnNzy3Ta57XtQ01XMWq2XPvaFrv/2sPrt8veprKtXacbh/WVV5QIuazs1ASQqf14WRJE2dUK2frntb1//Ls+rqDem22VP6l8UvjDA6BDYA52Wy7nleQ53KAoP/NH7jkw1a/cBV+s3nr9b/bN2nbe+caCVeFijR3IaJI9q/S1JdGElSR2ePXnn7kCRp5WsdumLK+ITlfmuUlw08EgfgvFR1z+lIrnuuKA1oxV0ztWDZuoR62i80b/LcvrIsur4fui/FL4zi3eQGsjbxveQ14hdGp44py+IRFjff3GEX80w7yCzOFffE655HwqvuefrkGjUvnK2ayjLPx+NS9DF4TWWZmhfO9s1Y4kNdGE0af4ou+2CNJOmmSz+gDW8dTFjul0Z52VTUvz069SNdnCvuW9Q0VQ+t3Jqym5GXoeqep0+u0frF12lN6z4tbWnTzoTzYqwWNU3V3IaJvjovUjXKk6TdB7p024en6J9vGaddB47qZ+veTljul0Z52VS0gc1MO0hXTzCsWUvWcq44bl5DnR5etV1SYmBf9a0/pNzmZHXPFaUBzZ9Rr/kz6hWOWHX3hXw/9GaqC6NQxOpLj2/y3MZPjfKyqSgfidOpH+na3N6pN97t5lwpAvG658qy9O54h1v3HCgxOnVMma/DWkrdKG8ofmmUl21FF9h06ke64udKxKZXV825kjnZaidA3XP2eV0Y7TnUoxu++5zn+sXcKC/X7V2K7pF4cqf+SeMr9didM7XhrYO6/Kzx2nf4uO75yUb1hk6sQ6d+f0o1MtZQOFdGLlftBFLVPUvS+bX+rHvOtPiF0e1J1Y4DVZUHVBYoKbqqpHy2dym6wPbq1D/l9FP0wM9f09d+2arv/+0Mzb24Tr/a1NG/3K8z7fhd8rnypb84T4eP9Wn5i29Jkr7ysfP1fnevfhx7LXGujFSu25R41T2/uu5Fff7T14z6ZyPKj43y8t02qqgCO1Wn/vZDPdq+NzrIwdaOw5p0WuWgdeKd+v1eP+UXXufKf21s1w8+c7mWv/iWjJH+cnqdbnrkxUHbcq4MT7xNiVc11Revn6bu3nBsXumwFixbl/FH1fG6Z2SenxrlDXUex0VDPDvnsVRkddipRjvqG/D4OxyR5zp+mmkH3ufKnkM9OnSsTxd94FRdM+1MbXvniDqPBQdty7mSPtqU+EcxN8orlPO4qO6wMznaEYpbqnPl8Q3tuuXySTqzukK/2NjuuS3nSvq82gncN+dcfeqyer3f3ae9nT1q7TiSsJx2Aig0XufxJy+r1z1XnyNJen3vEX35F5sTlmfjPC6qO+xMj3aE4pXqXHl62z5dc96ZumRSjZ7b+a7ntpwr6UtuJ3Bx/an6y+l1mve953Xnjzfokkk1g7ZhoggUmuTzeNqEat0/51z97aPrNPdfn9fD/7190DbZOI+LKrClwTPtJHc3ePT5N/TdZ3YlbEOnfn/ympUpGLZat/t9/ab1HXk9rOFcSZ9XO4GZU07T09v263gwoq7ekJ55fb/ntkwUgULhdR5/5NwztLp1nw7FqswO9wyuOpMyfx4XXWDTqR/p8jpXjJFmfLBGj2/wfhzOuZK+TM6gBeRLIZ3HRRfY2R7tCG4bONBB/FwpMdH/jOdOqNazX5mjF3e/r7fePzZoW86V9PWGwvrdtv2DZnVa/+ZBfezCWlWUlqiqPKDrPlTruT3tBFAovNq7vNT2nuY1TFTNKdHeB+MqvXshZPo8Lsr/EX7u1I/BTjbQwdlnVKmmMqy9nT265v8dPO4058rwDOyrmmzbO0f01Ja9WvOFq/V+d5+27On0/Bm0E0Ch8JrwZNeBLj3yhzY9vvDDilirbe8c1lf+a8ugbTN9HhdlYEv+7NSPwdIZ6OC+D/Xph7dfpT2HejhXRim5r+qk8ZX60e1XJLQjeeQPbXrkD6kb49BOAIXGa8KTJ1/t0JOvdqTcJhvncdEGtuSvTv0YLN2BDsIRq9t+9LKaF87W01/6KOfKCA23r2oqtBNAoUk1E9xQsnEeF10ddirF3Kkfg50sPJ5c9JGE1wMHOuBcGZmTjc0++bRK/eaBq3TJpHEp16GdAApRobSN8k1gw19OFh6fWvrSoPfiAx1gZLzG8Y8754wq/eAzl+sr/7VZW/YcHrScGbRQ6AphJjgCG0VpqPCQpG0P3zDoPQbsGLlU4/hL0mlV5Xr0s436QvMmvb73qOc6/89NF2v94usIaxS0eNuoJTc36PzaahkjlQWMjInOBLfk5oasnsdFXYcNfxoqPE6GiT3SEwpHdCwY7q/nj/dVTe7GJUlHjwfV0dmjK6aMV5vH51IWMLr+oloeg8MJ+WwbRWCj6AwVHicTH+iA2Z0GG6p73MJrpqb8fQfDVn/301f0k7tnqrs3rFWb30lYTp9ruCrXM8HxvwRFh0lgMu9k3eP+8ddbVWLkOZyrFG3Ud/djG/TTu2fpWF9Iz7x+oH8Zfa6B9PCXCUXHa6CDdBEeg6U/D/BgA8fyP3I8NGh+cRf7XCdXBwC5QmCjKHkNdDCQ142gi+GRbZnqW52KK32uTzZa3ryGOurgkXW0EveRgeNoF7uhJoGpOaVMncf6Br3vSnhkU/I5ktw9buE15+iOj0yRJP1fH/+Q/vOeWZKkD089Xd/9m0uHtS9X+lxvau/UrCVr9dDKrdq5v0vWRqsDrD0xWt6sJWu1ub0z34eKIscddpHz651BfKCDBUmPcieMrVDzwtl69Pk3E9Z3JTyyYahz5HBPMOEpxYY3D+pzV5+jx156Sw31NSovLVFpidHMKafp5TcP9q9XYqK/U9fH8U+uDjh1TKk+cWm9frbu7f51omUMa8GydfQjR1Zxh13E/H5n4DXQwYGjvbr2289qxUtvSYqGR6DE+PYP7cnOkX1HehPWb+04rIb6caquKFVfKKLX/nxIl0wapyumnKaX3zoR2FbRvtX56KuaKV7VAadWlum22Wd5rj9wtDwgG7jDLlLpNxQ6cWdQjNKZBGbc4V0FHx7ZkM45kiwUsWo/dEy3XD5Jr/z5kP6094hmn3O6ppxxSkIf69KSaN/qT14+ydmx2b1Gy/vqjRforNNP0eoHrtLzu97TN9b8KWF5fLS8+TPqc3mo8AkCuwh53Rl4zZoUF78z+M5Hy3N5mDlzsoEOWlp25fkIc89KI25MtuGtg7rnmnP0fz6xWTv2HdVDH79QWzsShxsd2D0u131VM8VrtLxv/c+fdF7tWM373gue28RHyyOwkQ08Ei9CJxtH20swHNHhnmCWjqhwMLFH1OGe4LDPkbiX3zyoCWMr9OrbnXqvq0+9wXBC/bXkfve4TIyWB2Qad9hFKNU42oESo298skGXnzVe+w4f1z0/2ajeUPSPdndfWO8eDeX6UJEn7x7tVXdfYqB+etYH9elZH5QkjR1Tpj2HenTro+sGbfvS7vc1bfGa/tfXfvvZhOXZ7B6Xqz7QjJaHQkRgF5mh7gymnH6KHvj5a/raL1v1/b+dobkX1+lXm05MwH48GGYcbR8IR6yOB8NK/u//H+v/rP9Y/2eVlhj95z2z9cMX3hjRz89097h89HRINVpeV29IVRVD74vR8pAto3okbow5zRjzO2PMrti/41OsFzbGbIp9rRrNPjG0+J2Bl/ZDPdq+94gkaWvHYU06rTJhuTHROwMUt+6+kIxJfVH29b+8SH/c/Z7WDhg+NF2Z7h6Xr54O8dHyknUeC+qVtw/p6S9eo6/NvcBzW9erA1C4RluH/aCktdbaaZLWxl576bHWXhr7+sQo94khDDWOdl/oRJ1lOKJBwW4tdwZ+UFVeKmu9z5FbLp+k+vGV+u7a4TXEy8Y8wPFW7J1JfcEH6u4Lq7MnqAXL1mU8tBc1TfWc9/gLzZt0w3efG9RCXGK0PGTXaAP7JkkrYt+vkDR/lD8Po5TqziAdY8oC3Bn4QKDEaEzZ4CC6uP5U3XP1Ofri468pRZ6rbtyYnPStHu6QqNnoAz3UaHmpMFoesmm0t1O11tq9se/3SapNsd4YY8xGSSFJ37TW/mqU+8UQTjaOtpeq8oDOHOu/Ub786syxFaoqDyecI7d/eIpqTilT8z3RPvlbOg7rwSdb+5dXlQf01RsvyMk8wF49HS6ZNE7f+tQlmv/IiyoxRr++/0rd/5+v9k/ykuk+0KlGy0vFz6PlITdMqkdj/SsY84wkr0vGxZJWWGtrBqx7yFo7qB7bGFNvre0wxpwj6feSrrPW7vZYb6GkhZJUW1t7eXNz83DKklFdXV2qrh7ZnWq+WUmv7z0yrK4lgRKjyWNLNNbRMo+Gy5/1SB3t6lL70ciwz5EP1Z2qXDyD2XWgK9YwLtHs6RcoUBJQaWlAXcd69Mq2xEf3Y8oCKZ8wjfRz7gmG9eZ73bJWinj8vSwx0ScNZ59RpUqPJxf55sfz2+Uyz5kz5xVrbaPXspMG9lCMMTskNVlr9xpj6iS1WGvPP8k2j0l6ylr7xFDrNTY22o0bN4742EarpaVFTU1Nedv/aG1u7xzWnUHzwtk6tHuT02UeKdc/65FoaWnR+KmXDvscycWIcOGI1bmLV3s+li8LGK26/yr1BsP65NKXBs2/bYzUtmSe513/aD7n3lB4yNHy5jZMLNg7a7+e366W2RiTMrBH+0h8laTbJX0z9u+vPXY+XtIxa22vMeYMSVdK+udR7hcnER9H+/blLysYjqQ1CUPLoGceKGYjOUdyYag+0DWnlOuU8oBKS4wqSgODLjay1Qf6ZKPlAbkw2sD+pqRfGGPulvS2pL+WJGNMo6R7rbWfk/QhSf9ujIko2sjtm9ba7aPcL9KQzjjahXxngOwrxHNkqJ4O//vmBn37tzs1+bRT9ODcC/T1VdsSlueiD7SrQ63CfaM6s62170u6zuP9jZI+F/v+JUkNo9kPRo47A5xMoZ0j8Z4O8cZkcZ+8rF6hSESrNr+jEiP9ctFH9OGpp+uPu9/vX4c+0ChmjCXuI4yjnT+hcERHjgcLfozpQjlHvPpA//LVDi362auSpIiV5v/bSwlhTR9oFDtGyQCyJB9DahaLeQ11enjVdknpd02kDzSKHXfYQBbka0jNYhHvA51uNyn6QMMPCGwgw/I9pGaxiLdir6ks8xwiVMrOkKhAoSKwgQwqhCE1i0m8FfuSmxtyMiQqUMiowwYyyGtITS/GqH9gkEwPqVlsCq0VO5Av3GEDGbS0ZbfnY/BJ4yu19h8+qm//9XT99kvX6APjTkxt2t0X1tKWtlweprMKpRU7kA/cYQMZEo5Y7TrQlXL52adX6Su/2KzXPOqsdx7oUjhiCSIAKXGHDWRIfEjNVDo6ezzDWjoxpCYApEJgAxky1JCaknRsiOlOczGkJgC3EdhAhsSH1BwJhtQEcDIENpBBXkNqngxDagJIB4ENZNC8hjqVBQb/t9pzqEc3fPc5z20YUhNAOghsIIMYUhP55spEMxg+WrkAGRYfUvP25S8rGI549suuKg+oLFCiFXfNZJQujNpQE80suiCo3lCYi8IiQGADWRAfUnNN6z4tbWnTzoQ/omO1qGmq5jZM5I8oRm1Te6fuSLo4DIajd9c79nepozasWUvWcnFYBAhsIEsYUhPZFp9oZqix6yPW9k80wyQpbqMOG8gBhtREpjHRjP8Q2ADgoHQnmhkoPtEM3MQjcQBwkNdEM5VlAT3y6ctUN26MSozR//f7XZJt718en2iGmeHcRGADgGNSTTTz0fPP1P4jx3XXYxskSWMrSnX+eYnrMNGMu3gkDgCOSTXRzI59R3X1tDP04I0X6Iop43W0d/CEMkw04y4CGwAck2qimTff69b/+t4L+tO+o/rKx87XA9cNHvKWiWbcRWAniY8SBACFKtVEMxPGVuh4MKxfberQvz/3hi7+wLhB6zDRjLu4zJL3KEEPXBjUN77zrO5tmqp5DXUMcAGgoCxqmqqHVm5NaHh2wcSx+tq8D8laq2DY6qFfbdXHTjuxDRPNuM33gX2yUYIeWrlVD6/azihBAArKvIY6Pbxqu6QTgf3crvf03L8+n7DewMBmohm3+fqReHyUoM6eoOd4z1K0G0R8lKDN7Z25PUAASIGJZvzHt4HNKEEAXBefaKamsizlPOwlxqimsoxhSYuAbx+JJ48SNGl8pVbcOVOvtR/SZR8cr2DXIa3r6dCXrj9Pp1dX6IvNr6ntQJfWtO5j0AEABeNkE83Uj+/V+sXXcmddBHwb2F6jBJ11+in6+/94VTsPbNH6r1ypmy6t1y0/+KP+4sJa3TfnXC386SuMEgSg4Aw10UxLSwthXSR8GdipRglqP9SjHfuPSpIOHj6qF9vekyT9ad8RTRpfKYlRggAUtvhEMyg+vqzDTjVKUF/oxCNya23/a2ulQEn0V8UoQQCAfPBlYKcaJSgdjBIEAMgHXwZ2qlGC0sEoQQCAfPBlYEvRUYIGdoPYc6hHN3z3uf7Xz6x7TWu27ktYxihBAIB88W1gz2uoU1lgeMVnlCAAQL74NrAZJQgA4BLfBraU3ihBVeUBRgkCAOSd75s7pxolSJLOrx2rRU1TNbdhInfWAIC88n1gS96jBL267kV9/tPX5PvQAACQ5PNH4l4YJQgAUIgIbAAAHEBgAwDgAAIbAAAHENgAADiAwAYAwAEENgAADiCwAQBwAIENAIADCGwAABxAYDsuFI7oyPGgwhGb70MBAGQRY4k7qDcU1urWvVraslu7YpOVhCJW502o1r1NUzWvoY7JSgCgyBDYjtnU3qk7lr+sYDii7r6wJCkYjt5d79jfpYdWbtXDq7ZrxV0zmQ4UAIoIj8Qdsrm9U7cuW6fOnmB/WCfr7gursyeoBcvWaXN7Z24PEACQNQS2I3pDYd2+/GX1BL2DOllPMLp+byi99QEAhW1UgW2M+StjzDZjTMQY0zjEejcaY3YYY9qMMQ+OZp9+tbp1r4LhyLC2CYYjWtO6L0tHBADIpdHeYW+V9ElJz6VawRgTkPSIpLmSLpR0qzHmwlHu13eWtuxOeAz+1RvP122zz+p//cXrp+meq89J2Ka7L6ylLW05O0YAQPaMKrCtta9ba3ecZLWZktqstW9Ya/skNUu6aTT79ZtwxGrXga6E957aslcfv6Su//X/aqjTU1veGbTtzgNddPkCgCKQizrsekntA17vib2HNHX3hVRaYhLe2/bOEZ1eXaEJYyv0obqxOtwT1N7DxwdtW1pi1N0XytWhAgCyxFg79N2XMeYZSRM9Fi221v46tk6LpK9Yazd6bH+LpButtZ+Lvb5N0ixr7f0e6y6UtFCSamtrL29ubh5eaTKoq6tL1dXVedt/staOw4Pem3XJBerp7VPVmAp1H+/Vlh1veG7bUD8urX0UWplzxY/lpsz+4cdyu1zmOXPmvGKt9WwTdtJ+2Nba60e5/w5Jkwe8nhR7z2tfyyQtk6TGxkbb1NQ0yl2PXEtLi/K5/2T/+zvPauf+xMfi0/bv0zc/dYnGn1KmRcvW6d2jgz/O82ur9flPfzStfRRamXMlE+UOhSM6FgyrqrxUgaSnIYXIj5+1H8ss+bPcxVrmXAycskHSNGPM2YoG9QJJf5uD/RaVRU1T9dDKrQkNz3Yd6FJVRUD7j/Tq3aO9g7apKg9oUdO5uTxMX2HEOQC5NNpuXTcbY/ZI+rCk3xhjno69/wFjzGpJstaGJN0v6WlJr0v6hbV22+gO23/mNdSpLDD447rxu8/r1kfXeW5TFijR3Aav2gyM1qb2Ts1aslYPrdyqnfu7ZG10xDlrT4w4N2vJWgavAZAxo20lvtJaO8laW2GtrbXW3hB7/x1r7bwB66221p5nrZ1qrV0y2oP2o4rSgFbcNVOVZendsVWWRdfnDi/zUo04t+3hG/q/Z8Q5AJnGSGcOmT65Rs0LZ6umskxV5d5BXFUeUE1lmZoXzmYs8SxgxDkA+UJgO2b65BqtX3ydltzcoPNrq2WMVBYwMkY6v3asltzcoPWLryOss4QR5wDkC7N1OaiiNKD5M+o1f0a9whGr7r6QM62TXZc84lw64iPOzZ/B8AMARo47bMcFSoxOHVNGWOeA14hz6WLEOQCjRWADafIacS5djDgHYLQIbCBNVeWlCo3wLjkUsaoqpwYKwMgR2ECaAiVG0yaMbLjD8yZUU20BYFQIbGAYFjVNTdml7qKvP+35PiPOAcgEAhsYhlQjzg2FEecAZAKBDQwDI84ByBcCGxgmRpwDkA80WwVGID7i3JrWfVra0qadCbN1jdWipqma2zCRO2sAGUNgAyPEiHMAconABjIgPuIcAGQLddgAADiAwAYAwAEENgAADiCwAQBwAIENAIADCGwAABxAYAMA4AACGwAABxDYAAA4gMAGAMABxlqb72PwZIx5V9LbeTyEMyS9l8f954Mfyyz5s9yU2T/8WG6Xy3yWtfZMrwUFG9j5ZozZaK1tzPdx5JIfyyz5s9yU2T/8WO5iLTOPxAEAcACBDQCAAwjs1Jbl+wDywI9llvxZbsrsH34sd1GWmTpsAAAcwB02AAAO8HVgG2NOM8b8zhizK/bv+BTrhY0xm2Jfqwa8f7YxZr0xps0Y87gxpjx3Rz8y6ZTZGHOpMeaPxphtxpgtxpi/GbDsMWPMmwN+H5fmtADDYIy50RizI/b5POixvCL2ubXFPscpA5Z9Lfb+DmPMDTk98FFKo9xfNsZsj322a40xZw1Y5nmuF7o0ynyHMebdAWX73IBlt8f+P+wyxtye2yMfuTTK/J0B5d1pjOkcsMzVz3m5MeaAMWZriuXGGPO92O9kizHmsgHLnPycE1hrffsl6Z8lPRj7/kFJ30qxXleK938haUHs+x9IWpTvMmWizJLOkzQt9v0HJO2VVBN7/ZikW/JdjjTKGZC0W9I5ksolbZZ0YdI6fy/pB7HvF0h6PPb9hbH1KySdHfs5gXyXKYPlniPplNj3i+Lljr32PNcL+SvNMt8h6fse254m6Y3Yv+Nj34/Pd5kyUeak9T8vabnLn3PsuK+RdJmkrSmWz5O0RpKRNFvSepc/5+QvX99hS7pJ0orY9yskzU93Q2OMkXStpCdGsn0enbTM1tqd1tpdse/fkXRAkmdH/gI2U1KbtfYNa22fpGZFyz7QwN/FE5Kui32uN0lqttb2WmvflNQW+3kuOGm5rbV/sNYei71cJ2lSjo8x09L5rFO5QdLvrLUHrbWHJP1O0o1ZOs5MGm6Zb5X085wcWRZZa5+TdHCIVW6S9BMbtU5SjTGmTu5+zgn8Hti11tq9se/3SapNsd4YY8xGY8w6Y8z82HunS+q01oZir/dIqs/eoWZMumWWJBljZip6Bb97wNtLYo+bvmOMqcjScY5WvaT2Aa+9Pp/+dWKf42FFP9d0ti1Uwz32uxW9I4nzOtcLXbpl/lTsvH3CGDN5mNsWmrSPO1blcbak3w9428XPOR2pfi+ufs4JSvN9ANlmjHlG0kSPRYsHvrDWWmNMqibzZ1lrO4wx50j6vTGmVdE/7gUpQ2VW7Mr0p5Jut9ZGYm9/TdGgL1e068RXJf1TJo4buWWM+YykRkkfHfD2oHPdWrvb+yc45b8l/dxa22uM+TtFn6xcm+djypUFkp6w1oYHvFesn3NRK/rAttZen2qZMWa/MabOWrs3Fk4HUvyMjti/bxhjWiTNkPSkoo9bSmN3Z5MkdWS8ACOQiTIbY06V9BtJi2OPluI/O3533muM+bGkr2Tw0DOpQ9LkAa+9Pp/4OnuMMaWSxkl6P81tC1Vax26MuV7RC7iPWmt74++nONcL/Q/5SctsrX1/wMsfKtqWI75tU9K2LRk/wswbzjm6QNJ9A99w9HNOR6rfi6ufcwK/PxJfJSneWvB2Sb9OXsEYMz7+2NcYc4akKyVtt9GWDH+QdMtQ2xegdMpcLmmlonVBTyQtq4v9axSt//ZsrVkANkiaZqIt+csV/aOV3Bp24O/iFkm/j32uqyQtiLUiP1vSNEkv5+i4R+uk5TbGzJD075I+Ya09MOB9z3M9Z0c+cumUuW7Ay09Iej32/dOSPhYr+3hJH4u9V+jSOb9ljLlA0UZWfxzwnqufczpWSfpsrLX4bEmHYzcZrn7OifLd6i2fX4rWV66VtEvSM5JOi73fKOmHse8/IqlV0VaYrZLuHrD9OYr+IW+T9F+SKvJdpgyV+TOSgpI2Dfi6NLbs97Hfw1ZJP5NUne8yDVHWeZJ2KnrnsDj23j8pGlSSNCb2ubXFPsdzBmy7OLbdDklz812WDJf7GUn7B3y2q2LvpzzXC/0rjTJ/Q9K2WNn+IOmCAdveFTsH2iTdme+yZKrMsdf/t6RvJm3n8uf8c0V7rQQVrYe+W9K9ku6NLTeSHon9TlolNbr+OQ/8YqQzAAAc4PdH4gAAOIHABgDAAQQ2AAAOILABAHAAgQ0AgAMIbAAAHEBgAwDgAAIbAAAH/P+zz1+Ax8OsNgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are using the entire data we will get to see the model overfitting too much and give the same results as the training data set. but not necessarily any new names. therefore we are going to split the data set into 3. those are train, dev and test in the ratio of 8:1:1\n",
        "\n",
        "train will be used to train the model (forward, backward and updating the parameter)\n",
        "\n",
        "dev will be used to tune the hyber parameters\n",
        "\n",
        "test will be used to validate the model"
      ],
      "metadata": {
        "id": "wnVOh6V6eKgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3 \n",
        "\n",
        "def build_dataset(words):  \n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] \n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xtest, Ytest = build_dataset(words[n2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmiAYB4uhRHq",
        "outputId": "1c91aa9b-8587-43a8-c064-fb973de59213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182484, 3]) torch.Size([182484])\n",
            "torch.Size([22869, 3]) torch.Size([22869])\n",
            "torch.Size([22793, 3]) torch.Size([22793])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,2),requires_grad=True)\n",
        "W1 = torch.randn((6,100), requires_grad=True)\n",
        "b1 = torch.randn(100, requires_grad=True)\n",
        "W2 = torch.randn((100, 27), requires_grad=True)\n",
        "b2 = torch.randn(27, requires_grad=True)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "stepi = []\n",
        "lrei = []\n",
        "lossi = []\n",
        "\n",
        "for i in range(10000):\n",
        "  #pick up random mini batches of 32 row from the data set in the each iteration\n",
        "  rand_index = torch.randint(0, Xtr.shape[0], (32,))\n",
        "\n",
        "  #forward pass\n",
        "  emb = C[Xtr[rand_index]]\n",
        "  logits = ((emb.view(-1,6) @ W1 + b1).tanh()) @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Ytr[rand_index])\n",
        "\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  #lr = lrs[i]\n",
        "  #tune the parameters\n",
        "  for p in parameters:\n",
        "    p.data += -0.1 * p.grad\n",
        "\n",
        "  stepi.append(i)\n",
        "  #lrei.append(lr)\n",
        "  lossi.append(loss.item())"
      ],
      "metadata": {
        "id": "qAfNk0xPhOhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr] \n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "loss\n",
        "print(f'loss in training dataset: {loss.item()}')\n",
        "\n",
        "emb = C[Xdev] \n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "loss\n",
        "print(f'loss in dev dataset: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8zO0VLKk7eG",
        "outputId": "3f5cfa98-8f89-4677-f60b-af9adccd3af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in training dataset: 2.483764410018921\n",
            "loss in dev dataset: 2.487154483795166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here the loss in dev and training are about equal. that means data is not overfiting instead it's underfitting. therefore we need to increase the parameters. so better try the same with bit higher neurons in the hidden layer"
      ],
      "metadata": {
        "id": "6kG0blOZojtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,2),requires_grad=True)\n",
        "W1 = torch.randn((6,300), requires_grad=True)\n",
        "b1 = torch.randn(300, requires_grad=True)\n",
        "W2 = torch.randn((300, 27), requires_grad=True)\n",
        "b2 = torch.randn(27, requires_grad=True)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "08cR07f3qaVi"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stepi = []\n",
        "lrei = []\n",
        "lossi = []\n",
        "\n",
        "for i in range(50000):\n",
        "  #pick up random mini batches of 32 row from the data set in the each iteration\n",
        "  rand_index = torch.randint(0, Xtr.shape[0], (32,))\n",
        "\n",
        "  #forward pass\n",
        "  emb = C[Xtr[rand_index]]\n",
        "  logits = ((emb.view(-1,6) @ W1 + b1).tanh()) @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Ytr[rand_index])\n",
        "\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  #lr = lrs[i]\n",
        "  #tune the parameters\n",
        "  for p in parameters:\n",
        "    p.data += -0.1 * p.grad\n",
        "\n",
        "  stepi.append(i)\n",
        "  #lrei.append(lr)\n",
        "  lossi.append(loss.item())"
      ],
      "metadata": {
        "id": "MoyJYzCtoz4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr] \n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "loss\n",
        "print(f'loss in training dataset: {loss.item()}')\n",
        "\n",
        "emb = C[Xdev] \n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "loss\n",
        "print(f'loss in dev dataset: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN79zZXlo4v0",
        "outputId": "4991c02d-7ead-43f0-aed2-8548f2f112d5"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in training dataset: 2.3873119354248047\n",
            "loss in dev dataset: 2.3972957134246826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever we try the retrain again again it's not squashing below a particular value. the reason for this could be the embeding dimension"
      ],
      "metadata": {
        "id": "CubptZJftHqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27,10),requires_grad=True)\n",
        "W1 = torch.randn((30,300), requires_grad=True)\n",
        "b1 = torch.randn(300, requires_grad=True)\n",
        "W2 = torch.randn((300, 27), requires_grad=True)\n",
        "b2 = torch.randn(27, requires_grad=True)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "M1Qqeel9tiRu"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stepi = []\n",
        "lrei = []\n",
        "lossi = []\n",
        "\n",
        "for i in range(50000):\n",
        "  #pick up random mini batches of 32 row from the data set in the each iteration\n",
        "  rand_index = torch.randint(0, Xtr.shape[0], (32,))\n",
        "\n",
        "  #forward pass\n",
        "  emb = C[Xtr[rand_index]]\n",
        "  logits = ((emb.view(-1,30) @ W1 + b1).tanh()) @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Ytr[rand_index])\n",
        "\n",
        "  #backward\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  #lr = lrs[i]\n",
        "  #tune the parameters\n",
        "  for p in parameters:\n",
        "    p.data += -0.1 * p.grad\n",
        "\n",
        "  stepi.append(i)\n",
        "  #lrei.append(lr)\n",
        "  lossi.append(loss.item())\n",
        "\n",
        "emb = C[Xtr] \n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "loss\n",
        "print(f'loss in training dataset: {loss.item()}')\n",
        "\n",
        "emb = C[Xdev] \n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "loss\n",
        "print(f'loss in dev dataset: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lCozkGetn0W",
        "outputId": "6f566ed5-93a6-4661-a996-ea79955628d5"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss in training dataset: 2.1987736225128174\n",
            "loss in dev dataset: 2.281503438949585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "for _ in range(20):\n",
        "    \n",
        "    out = []\n",
        "    context = [0] * block_size\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] \n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "    \n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEpVjXao-iEQ",
        "outputId": "9e699914-1e2c-4766-a803-755b0da26a6a"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dex.\n",
            "maleal.\n",
            "makilani.\n",
            "ahreel.\n",
            "mckina.\n",
            "mella.\n",
            "kamaiah.\n",
            "samiyah.\n",
            "jakhi.\n",
            "mothi.\n",
            "mckiella.\n",
            "kinzie.\n",
            "darenley.\n",
            "mcki.\n",
            "suhakainen.\n",
            "matbs.\n",
            "mhuringa.\n",
            "tahivan.\n",
            "mydra.\n",
            "anesley.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyN6rB-B-oZe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrEqWaiX1QXqX1L4R34ItZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}